# VoiceFlow STT Agent - Prueba de Concepto

Este proyecto implementa un agente de Speech-to-Text (STT) como parte de un sistema multiagente para planificaci√≥n de rutas de ocio accesibles.

## üèóÔ∏è Arquitectura

El proyecto sigue los principios SOLID y est√° dise√±ado para ser:
- **Escalable**: F√°cil agregar nuevos servicios STT
- **Testeable**: Interfaces bien definidas para mocking
- **Configurable**: Sin necesidad de modificar c√≥digo
- **Modular**: Separaci√≥n clara de responsabilidades

### Estructura del Proyecto

```
src/
‚îú‚îÄ‚îÄ interfaces/
‚îÇ   ‚îî‚îÄ‚îÄ stt_interface.py      # Interfaz base para servicios STT
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ azure_speech_service.py   # Implementaci√≥n Azure Speech
‚îÇ   ‚îî‚îÄ‚îÄ whisper_services.py       # Implementaciones Whisper (local y API)
‚îú‚îÄ‚îÄ factory.py                # Factory para crear servicios STT
‚îî‚îÄ‚îÄ voiceflow_stt_agent.py   # Agente principal STT
```

## ‚öôÔ∏è Configuraci√≥n

1. **Copiar archivo de configuraci√≥n:**
   ```bash
   cp .env.example .env
   ```

2. **Configurar variables de entorno en `.env`:**

   ### Para Azure Speech Services:
   ```env
   STT_SERVICE=azure
   AZURE_SPEECH_KEY=tu_clave_azure
   AZURE_SPEECH_REGION=tu_region_azure
   ```

   ### Para Whisper Local:
   ```env
   STT_SERVICE=whisper_local
   WHISPER_MODEL=base
   ```

   ### Para Whisper API:
   ```env
   STT_SERVICE=whisper_api
   OPENAI_API_KEY=tu_clave_openai
   ```

## üöÄ Instalaci√≥n

1. **Instalar dependencias:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Para usar Azure Speech (recomendado para PoC):**
   ```bash
   pip install azure-cognitiveservices-speech
   ```

3. **Para usar Whisper local:**
   ```bash
   pip install openai-whisper
   ```

4. **Para usar Whisper API:**
   ```bash
   pip install openai
   ```

## üìã Servicios STT Disponibles

### 1. Azure Speech Services (Recomendado)
- ‚úÖ **Ideal para PoC universitaria**
- ‚úÖ Tier gratuito: 5 horas/mes
- ‚úÖ Cr√©ditos Azure for Students suficientes
- ‚úÖ Muy preciso
- ‚úÖ Soporta m√∫ltiples idiomas

### 2. OpenAI Whisper Local
- ‚úÖ **Completamente gratuito**
- ‚úÖ Funciona offline
- ‚úÖ Muy preciso
- ‚ö†Ô∏è Requiere recursos computacionales

### 3. OpenAI Whisper API
- ‚úÖ Muy preciso
- ‚úÖ No requiere recursos locales
- ‚ö†Ô∏è Costo: ~$0.006 por minuto

## üìÅ Formatos de Audio Soportados

- **WAV** (recomendado para m√°xima calidad)
- **MP3**
- **M4A**
- **FLAC**
- **OGG**
- **WEBM** (solo Whisper)

## üéØ Uso B√°sico

```python
import asyncio
from src.voiceflow_stt_agent import VoiceflowSTTAgent

async def main():
    # Crear agente desde configuraci√≥n
    agent = VoiceflowSTTAgent.create_from_config()
    
    # Verificar estado del agente
    health = await agent.health_check()
    print(f"Estado del agente: {health['status']}")
    
    # Transcribir audio
    transcription = await agent.transcribe_audio("path/to/audio.wav")
    print(f"Transcripci√≥n: {transcription}")
    
    # Obtener informaci√≥n del servicio
    info = agent.get_service_info()
    print(f"Servicio: {info['service_info']['service_name']}")

if __name__ == "__main__":
    asyncio.run(main())
```

## üîß Extensibilidad

### Agregar un Nuevo Servicio STT

1. **Crear clase que implemente `STTServiceInterface`:**
   ```python
   from src.interfaces.stt_interface import STTServiceInterface
   
   class MiNuevoServicioSTT(STTServiceInterface):
       # Implementar m√©todos abstractos
       pass
   ```

2. **Registrar en el factory:**
   ```python
   from src.factory import STTServiceFactory
   
   STTServiceFactory.register_service("mi_servicio", MiNuevoServicioSTT)
   ```

## üß™ Testing

La arquitectura permite f√°cil testing mediante mocking:

```python
import pytest
from unittest.mock import AsyncMock
from src.voiceflow_stt_agent import VoiceflowSTTAgent

@pytest.mark.asyncio
async def test_transcription():
    # Mock del servicio STT
    mock_service = AsyncMock()
    mock_service.transcribe_audio.return_value = "Texto transcrito"
    mock_service.is_service_available.return_value = True
    
    # Crear agente con mock
    agent = VoiceflowSTTAgent(mock_service)
    
    # Probar transcripci√≥n
    result = await agent.transcribe_audio("test.wav")
    assert result == "Texto transcrito"
```

## üìä Monitoreo y Debugging

El agente mantiene historial de transcripciones:

```python
# Obtener historial
history = agent.get_transcription_history()

# Ver estad√≠sticas
info = agent.get_service_info()
print(f"Transcripciones realizadas: {info['transcription_count']}")
```

## üîç Troubleshooting

### Error: "Import could not be resolved"
- Los errores de import son normales hasta instalar las dependencias
- Ejecuta: `pip install -r requirements.txt`

### Error: "Servicio STT no est√° disponible"
- Verifica las variables de entorno en `.env`
- Para Azure: confirma `AZURE_SPEECH_KEY` y `AZURE_SPEECH_REGION`
- Para OpenAI: confirma `OPENAI_API_KEY`

### Error: "Formato de audio no soportado"
- Convierte el audio a WAV 16kHz mono para mejor compatibilidad
- Usa herramientas como FFmpeg para conversi√≥n

## ÔøΩ Documentaci√≥n Adicional

Para desarrolladores y futuros mantenedores del proyecto:

- **[ARCHITECTURE.md](ARCHITECTURE.md)** - Decisiones de arquitectura, patrones SOLID, y contexto t√©cnico detallado
- **[DEVELOPMENT.md](DEVELOPMENT.md)** - Gu√≠a completa de desarrollo, testing, y workflows
- **[API_REFERENCE.md](API_REFERENCE.md)** - Documentaci√≥n completa de todas las clases, m√©todos y ejemplos de uso

## ÔøΩüìà Pr√≥ximos Pasos

1. **Integraci√≥n con Sistema Multiagente**
2. **Optimizaci√≥n de performance**
3. **Manejo de audio en tiempo real** 
4. **M√©tricas avanzadas y logging**
5. **Interfaz web para testing**

---

## ü§ù Contribuci√≥n

Para agregar nuevas funcionalidades:
1. Mant√©n los principios SOLID (ver [ARCHITECTURE.md](ARCHITECTURE.md))
2. Implementa tests unitarios (ver [DEVELOPMENT.md](DEVELOPMENT.md))
3. Actualiza la documentaci√≥n correspondiente
4. Usa type hints y docstrings (ver [API_REFERENCE.md](API_REFERENCE.md))
